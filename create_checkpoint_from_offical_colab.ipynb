{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elisim/Informer2020/blob/hf/create_checkpoint_from_offical_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IM6CZzW_CH0"
      },
      "source": [
        "# Informer Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdaIHYx4_ECL"
      },
      "source": [
        "## Download code and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA_i2gbl-rn-",
        "outputId": "8600a87f-7578-4d95-f8a0-e9521ae696fc"
      },
      "source": [
        "!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
        "!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Informer2020'...\n",
            "remote: Enumerating objects: 573, done.\u001b[K\n",
            "remote: Total 573 (delta 0), reused 0 (delta 0), pack-reused 573\u001b[K\n",
            "Receiving objects: 100% (573/573), 6.48 MiB | 17.37 MiB/s, done.\n",
            "Resolving deltas: 100% (328/328), done.\n",
            "Cloning into 'ETDataset'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 187 (delta 25), reused 20 (delta 20), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (187/187), 3.86 MiB | 2.07 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "ETDataset  Informer2020  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5GFng7v7Eq0"
      },
      "source": [
        "import sys\n",
        "if not 'Informer2020' in sys.path:\n",
        "    sys.path += ['Informer2020']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW9TS6jp_YXc"
      },
      "source": [
        "# !pip install -r ./Informer2020/requirements.txt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIjZdN5e_SWe"
      },
      "source": [
        "## Experiments: Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdt-Kwc_RRZ"
      },
      "source": [
        "from utils.tools import dotdict\n",
        "from exp.exp_informer import Exp_Informer\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mx2dnwY9dWi"
      },
      "source": [
        "args = dotdict()\n",
        "\n",
        "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
        "\n",
        "args.data = 'ETTh1' # data\n",
        "args.root_path = './ETDataset/ETT-small/' # root path of data file\n",
        "args.data_path = 'ETTh1.csv' # data file\n",
        "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
        "args.target = 'OT' # target feature in S or MS task\n",
        "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
        "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
        "\n",
        "args.seq_len = 96 # input sequence length of Informer encoder\n",
        "args.label_len = 48 # start token length of Informer decoder\n",
        "args.pred_len = 24 # prediction sequence length\n",
        "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
        "\n",
        "args.enc_in = 7 # encoder input size\n",
        "args.dec_in = 7 # decoder input size\n",
        "args.c_out = 7 # output size\n",
        "args.factor = 5 # probsparse attn factor\n",
        "args.d_model = 512 # dimension of model\n",
        "args.n_heads = 8 # num of heads\n",
        "args.e_layers = 2 # num of encoder layers\n",
        "args.d_layers = 1 # num of decoder layers\n",
        "args.d_ff = 2048 # dimension of fcn in model\n",
        "args.dropout = 0.05 # dropout\n",
        "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'gelu' # activation\n",
        "args.distil = True # whether to use distilling in encoder\n",
        "args.output_attention = False # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "args.padding = 0\n",
        "args.freq = 'h'\n",
        "\n",
        "args.batch_size = 32 \n",
        "args.learning_rate = 0.0001\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "args.use_amp = False # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 0\n",
        "args.itr = 1\n",
        "args.train_epochs = 6\n",
        "args.patience = 3\n",
        "args.des = 'exp'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "args.gpu = 0\n",
        "\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_BCYODAwKl9"
      },
      "source": [
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "if args.use_gpu and args.use_multi_gpu:\n",
        "    args.devices = args.devices.replace(' ','')\n",
        "    device_ids = args.devices.split(',')\n",
        "    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    args.gpu = args.device_ids[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53o3pZ809p-a"
      },
      "source": [
        "# Set augments by using data name\n",
        "data_parser = {\n",
        "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "}\n",
        "if args.data in data_parser.keys():\n",
        "    data_info = data_parser[args.data]\n",
        "    args.data_path = data_info['data']\n",
        "    args.target = data_info['T']\n",
        "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ5Q2vyKwSfk"
      },
      "source": [
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywY-umrw-mHO"
      },
      "source": [
        "print('Args in experiment:')\n",
        "print(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVHZhRB4-on9"
      },
      "source": [
        "Exp = Exp_Informer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "928tzaA2AA2g"
      },
      "source": [
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
        "                args.seq_len, args.label_len, args.pred_len,\n",
        "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
        "\n",
        "    # set experiments\n",
        "    exp = Exp(args)\n",
        "    \n",
        "    # train\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)\n",
        "    \n",
        "    # test\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}